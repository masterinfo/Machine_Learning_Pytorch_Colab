{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVQJCQ81iw2FTLW/65Gyoo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masterinfo/Machine_Learning_Pytorch_Colab/blob/main/nltk_tuto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_K-wRUMpcJV",
        "outputId": "aaab3fb7-cd1b-4762-9090-04d7ecaf04d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['John', 'works', 'at', 'LinkedIn', 'in', 'Graz', 'which', 'is', 'a', 'big', 'city', 'in', 'Austria', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# tokenisation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "token = nltk.word_tokenize(u'John works at LinkedIn in Graz which is a big city in Austria.')\n",
        "\n",
        "print(token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = nltk.word_tokenize(u'et maintenant un exemple en Francais.')\n",
        "\n",
        "print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrcFUbW7qPIt",
        "outputId": "73b0dcb2-20d6-47f1-c0b9-1de1c339d246"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['et', 'maintenant', 'un', 'exemple', 'en', 'Francais', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tag decomposition ( 48 tags possible)"
      ],
      "metadata": {
        "id": "QwV26SFuKapo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "token = word_tokenize(u'John works at LinkedIn in Graz which is a big city in Austria.')\n",
        "\n",
        "print(ne_chunk(pos_tag(token)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBo8CB6uKdMm",
        "outputId": "8dc534c6-0967-4e38-af2d-81fd26064231"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON John/NNP)\n",
            "  works/VBZ\n",
            "  at/IN\n",
            "  (ORGANIZATION LinkedIn/NNP)\n",
            "  in/IN\n",
            "  (GPE Graz/NNP)\n",
            "  which/WDT\n",
            "  is/VBZ\n",
            "  a/DT\n",
            "  big/JJ\n",
            "  city/NN\n",
            "  in/IN\n",
            "  (GSP Austria/NNP)\n",
            "  ./.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nous commençons par charger la librairie d'analyse PorterStemmer. PorterStemmer est un lemmatiseur**\n",
        "\n",
        "a lemmatisation s'est parfaitement bien passée, donc, on a une transformation en forme canonique masculin, singulier, et les verbes à l'infinitif"
      ],
      "metadata": {
        "id": "T3l1ujQANck6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "ps.stem('saying')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F-qXFCbBNaKm",
        "outputId": "4c3dc6fc-448a-496e-f9e1-db2c1ea33049"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'say'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps.stem(\"enchantée\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eEVgMwfXOXBB",
        "outputId": "963348b3-edc2-42fb-f1a7-16a25f08e496"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'enchanté'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " On charge la bibliothèque d'analyse, nous allons utiliser le SnowballStemmer. C'est un algorithme classique de Text Mining chargé de raciniser. L'exemple que nous allons faire est un exemple en français"
      ],
      "metadata": {
        "id": "Uwwv8HpKO9vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "snow = SnowballStemmer('french')\n",
        "\n",
        "print(snow.stem('navigatrice'))\n",
        "\n",
        "print(snow.stem('navigateur'))\n",
        "\n",
        "print(snow.stem('naviguer'))\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5lT9DI3O99g",
        "outputId": "e6439d48-5024-4ac6-e7c7-96046f4afa3d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "navig\n",
            "navig\n",
            "navigu\n"
          ]
        }
      ]
    }
  ]
}